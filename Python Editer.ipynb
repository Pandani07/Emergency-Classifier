{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Description"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>callDateTime</th>\n      <th>priority</th>\n      <th>district</th>\n      <th>description</th>\n      <th>callNumber</th>\n      <th>incidentLocation</th>\n      <th>location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2015-07-13 10:41:00</td>\n      <td>Medium</td>\n      <td>CD</td>\n      <td>SEE TEXT</td>\n      <td>P151941002</td>\n      <td>0 N CALVERT ST</td>\n      <td>(39.2899299,-76.6123462)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2015-07-13 10:47:00</td>\n      <td>Medium</td>\n      <td>CD</td>\n      <td>911/NO  VOICE</td>\n      <td>P151941003</td>\n      <td>600 E FAYETTE ST</td>\n      <td>(39.2906737,-76.6071600)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2015-07-13 10:42:00</td>\n      <td>Medium</td>\n      <td>CD</td>\n      <td>911/NO  VOICE</td>\n      <td>P151941004</td>\n      <td>200 E BALTIMORE ST</td>\n      <td>(39.2898910,-76.6120720)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2015-07-13 10:45:00</td>\n      <td>Low</td>\n      <td>CD</td>\n      <td>PRKG COMPLAINT</td>\n      <td>P151941005</td>\n      <td>800 PARK AV</td>\n      <td>(39.2985163,-76.6184754)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2015-07-13 10:46:00</td>\n      <td>Medium</td>\n      <td>SW</td>\n      <td>AUTO THEFT</td>\n      <td>P151941006</td>\n      <td>3500 CLIFTON AV</td>\n      <td>(39.3112130,-76.6763150)</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Unnamed: 0         callDateTime priority district     description  \\\n0           0  2015-07-13 10:41:00   Medium       CD        SEE TEXT   \n1           1  2015-07-13 10:47:00   Medium       CD   911/NO  VOICE   \n2           2  2015-07-13 10:42:00   Medium       CD   911/NO  VOICE   \n3           3  2015-07-13 10:45:00      Low       CD  PRKG COMPLAINT   \n4           4  2015-07-13 10:46:00   Medium       SW      AUTO THEFT   \n\n   callNumber    incidentLocation                  location  \n0  P151941002      0 N CALVERT ST  (39.2899299,-76.6123462)  \n1  P151941003    600 E FAYETTE ST  (39.2906737,-76.6071600)  \n2  P151941004  200 E BALTIMORE ST  (39.2898910,-76.6120720)  \n3  P151941005         800 PARK AV  (39.2985163,-76.6184754)  \n4  P151941006     3500 CLIFTON AV  (39.3112130,-76.6763150)  "
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Importing all the libraries"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/dsxuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
                },
                {
                    "data": {
                        "text/plain": "True"
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import string\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nnltk.download('stopwords')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Mapping priorities to numeric  values and converting the description of the emergency to string"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "df_data_1['priority'] = df_data_1['priority'].map({\n    'Medium':2,\n    'Low':1,\n    'High':3\n    })\ndf_data_1['priority'] = df_data_1['priority'].fillna(value = 0)\n\ndf_data_1['description'] = df_data_1['description'].astype('str')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Creating a bag of words"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Success\n"
                }
            ],
            "source": "def process(text):\n    nopunc = [char for char in text if char not in string.punctuation]\n    nopunc = ''.join(nopunc)\n    cleaned_text = [text for text in nopunc.split() if text.lower() not in stopwords.words('english')]\n    return cleaned_text\ntext_bow = CountVectorizer(analyzer = process).fit_transform(df_data_1['description'])\nprint(\"Success\")\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Splitting into training and test set"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "X_train,  X_test, Y_train,Y_test = train_test_split(text_bow, df_data_1['priority'] , test_size=0.25, random_state = 0)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Using the multinomialnb classifier to predict the test values"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[ 69465   4650   7945    292]\n [  1660 134993  16823   5348]\n [  1090   9296 340365     77]\n [    70    415    667 106823]]\n"
                }
            ],
            "source": "classifier = MultinomialNB().fit(X_train, Y_train)\npred = classifier.predict(X_test)\ncm = confusion_matrix(Y_test, pred)\nprint(cm)"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "0.9309507856664271\n              precision    recall  f1-score   support\n\n         0.0       0.96      0.84      0.90     82352\n         1.0       0.90      0.85      0.88    158824\n         2.0       0.93      0.97      0.95    350828\n         3.0       0.95      0.99      0.97    107975\n\n   micro avg       0.93      0.93      0.93    699979\n   macro avg       0.94      0.91      0.92    699979\nweighted avg       0.93      0.93      0.93    699979\n\n"
                }
            ],
            "source": "print(accuracy_score(Y_test, pred))\nprint(classification_report(Y_test, pred))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}