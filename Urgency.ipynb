{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Description"}, {"metadata": {}, "cell_type": "code", "source": "\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_c54f2e7f40e0418cb540ed70e11f9722 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='SyrI4oCfA7rN6fy-o2SGHEDA-wxByeikJ5KBz9d6NP0Q',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\nbody = client_c54f2e7f40e0418cb540ed70e11f9722.get_object(Bucket='urgency-donotdelete-pr-fbcrmlm7w8reii',Key='911_calls_for_service.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()\n", "execution_count": 1, "outputs": [{"output_type": "execute_result", "execution_count": 1, "data": {"text/plain": "   Unnamed: 0         callDateTime priority district     description  \\\n0           0  2015-07-13 10:41:00   Medium       CD        SEE TEXT   \n1           1  2015-07-13 10:47:00   Medium       CD   911/NO  VOICE   \n2           2  2015-07-13 10:42:00   Medium       CD   911/NO  VOICE   \n3           3  2015-07-13 10:45:00      Low       CD  PRKG COMPLAINT   \n4           4  2015-07-13 10:46:00   Medium       SW      AUTO THEFT   \n\n   callNumber    incidentLocation                  location  \n0  P151941002      0 N CALVERT ST  (39.2899299,-76.6123462)  \n1  P151941003    600 E FAYETTE ST  (39.2906737,-76.6071600)  \n2  P151941004  200 E BALTIMORE ST  (39.2898910,-76.6120720)  \n3  P151941005         800 PARK AV  (39.2985163,-76.6184754)  \n4  P151941006     3500 CLIFTON AV  (39.3112130,-76.6763150)  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>callDateTime</th>\n      <th>priority</th>\n      <th>district</th>\n      <th>description</th>\n      <th>callNumber</th>\n      <th>incidentLocation</th>\n      <th>location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2015-07-13 10:41:00</td>\n      <td>Medium</td>\n      <td>CD</td>\n      <td>SEE TEXT</td>\n      <td>P151941002</td>\n      <td>0 N CALVERT ST</td>\n      <td>(39.2899299,-76.6123462)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2015-07-13 10:47:00</td>\n      <td>Medium</td>\n      <td>CD</td>\n      <td>911/NO  VOICE</td>\n      <td>P151941003</td>\n      <td>600 E FAYETTE ST</td>\n      <td>(39.2906737,-76.6071600)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2015-07-13 10:42:00</td>\n      <td>Medium</td>\n      <td>CD</td>\n      <td>911/NO  VOICE</td>\n      <td>P151941004</td>\n      <td>200 E BALTIMORE ST</td>\n      <td>(39.2898910,-76.6120720)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2015-07-13 10:45:00</td>\n      <td>Low</td>\n      <td>CD</td>\n      <td>PRKG COMPLAINT</td>\n      <td>P151941005</td>\n      <td>800 PARK AV</td>\n      <td>(39.2985163,-76.6184754)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2015-07-13 10:46:00</td>\n      <td>Medium</td>\n      <td>SW</td>\n      <td>AUTO THEFT</td>\n      <td>P151941006</td>\n      <td>3500 CLIFTON AV</td>\n      <td>(39.3112130,-76.6763150)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Importing all the libraries"}, {"metadata": {}, "cell_type": "code", "source": "import string\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nnltk.download('stopwords')", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/dsxuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n", "name": "stderr"}, {"output_type": "execute_result", "execution_count": 2, "data": {"text/plain": "True"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Mapping priorities to numeric  values and converting the description of the emergency to string"}, {"metadata": {}, "cell_type": "code", "source": "df_data_1['priority'] = df_data_1['priority'].map({\n    'Medium':2,\n    'Low':1,\n    'High':3\n    })\ndf_data_1['priority'] = df_data_1['priority'].fillna(value = 0)\n\ndf_data_1['description'] = df_data_1['description'].astype('str')", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Creating a bag of words"}, {"metadata": {}, "cell_type": "code", "source": "def process(text):\n    nopunc = [char for char in text if char not in string.punctuation]\n    nopunc = ''.join(nopunc)\n    cleaned_text = [text for text in nopunc.split() if text.lower() not in stopwords.words('english')]\n    return cleaned_text\ntext_bow = CountVectorizer(analyzer = process).fit_transform(df_data_1['description'])\nprint(\"Success\")\n", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "Success\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Splitting into training and test set"}, {"metadata": {}, "cell_type": "code", "source": "X_train,  X_test, Y_train,Y_test = train_test_split(text_bow, df_data_1['priority'] , test_size=0.25, random_state = 0)\n", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Using the multinomialnb classifier to predict the test values"}, {"metadata": {}, "cell_type": "code", "source": "classifier = MultinomialNB().fit(X_train, Y_train)\npred = classifier.predict(X_test)\ncm = confusion_matrix(Y_test, pred)\nprint(cm)", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "[[ 69465   4650   7945    292]\n [  1660 134993  16823   5348]\n [  1090   9296 340365     77]\n [    70    415    667 106823]]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "print(accuracy_score(Y_test, pred))\nprint(classification_report(Y_test, pred))", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "0.9309507856664271\n              precision    recall  f1-score   support\n\n         0.0       0.96      0.84      0.90     82352\n         1.0       0.90      0.85      0.88    158824\n         2.0       0.93      0.97      0.95    350828\n         3.0       0.95      0.99      0.97    107975\n\n   micro avg       0.93      0.93      0.93    699979\n   macro avg       0.94      0.91      0.92    699979\nweighted avg       0.93      0.93      0.93    699979\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}